{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e8d5ba-7473-444c-b75e-defc4d2f26ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **前置操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ea3f52-e5e9-42d9-a84e-d966060e12c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# 数据可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 特征工程\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# 模型相关\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 其他\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set(palette='muted', style='whitegrid')\n",
    "np.random.seed(13154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a55b196-bb75-487f-b09b-a137d0746c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_cleanned.csv\")\n",
    "test = pd.read_csv(\"test_cleanned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9eb0d8-ab0f-43ee-b7b9-a2309cf1c2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 106), (75818, 105))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape , test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b499148-337d-4dbb-95d1-a3a1350c7dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_medio_var12_ult1</th>\n",
       "      <th>saldo_medio_var12_ult3</th>\n",
       "      <th>saldo_medio_var13_corto_ult1</th>\n",
       "      <th>saldo_medio_var13_corto_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>var15_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.576564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>240.75</td>\n",
       "      <td>10.805234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.117417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>138.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.066763</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>40501.08</td>\n",
       "      <td>13501.47</td>\n",
       "      <td>85501.89</td>\n",
       "      <td>11.356294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.672584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2      0                 0.0                      0.0   \n",
       "1   3     2      1                 0.0                      0.0   \n",
       "2   4     2      0                 0.0                      0.0   \n",
       "3   8     2      1                 0.0                    195.0   \n",
       "4  10     2      1                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var41_comer_ult1  imp_op_var41_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                    195.0                    195.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var41_efect_ult1  imp_op_var41_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var5_hace3  saldo_medio_var5_ult1  saldo_medio_var5_ult3  \\\n",
       "0                    0.00                   0.00                   0.00   \n",
       "1                   88.89                   0.00                   0.00   \n",
       "2                    0.18                   3.00                   2.07   \n",
       "3                    0.00                  91.56                 138.84   \n",
       "4                    0.30               40501.08               13501.47   \n",
       "\n",
       "   saldo_medio_var12_ult1  saldo_medio_var12_ult3  \\\n",
       "0                    0.00                0.000000   \n",
       "1                    0.00                0.000000   \n",
       "2                    0.00                0.000000   \n",
       "3                    0.00                0.000000   \n",
       "4                85501.89               11.356294   \n",
       "\n",
       "   saldo_medio_var13_corto_ult1  saldo_medio_var13_corto_ult3      var38  \\\n",
       "0                           0.0                          0.00  10.576564   \n",
       "1                         300.0                        240.75  10.805234   \n",
       "2                           0.0                          0.00  11.117417   \n",
       "3                           0.0                          0.00  11.066763   \n",
       "4                           0.0                          0.00  11.672584   \n",
       "\n",
       "   TARGET  var15_0  \n",
       "0       0        1  \n",
       "1       0        1  \n",
       "2       0        1  \n",
       "3       0        1  \n",
       "4       0        1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9e5c7-6aac-4f2d-bc64-32d7cd65ab99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **特征工程（Feature Engineering）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae85d3f-6aa2-4cea-8ff3-974d8d39f3e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. 特征构造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7fbf7-6b92-41fc-a6c0-e04d885e5468",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **规范定类数据**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d58fc-41d0-4c21-89f4-59d48a9e441b",
   "metadata": {},
   "source": [
    "- 由于机器学习仅接受数值型数据，这里想找到所有潜在的定类数据，对定类数据进行编码处理，以便于后续的处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320146c3-c654-40b7-931e-6bfcf5402921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 106 entries, ID to var15_0\n",
      "dtypes: category(43), float64(29), int64(34)\n",
      "memory usage: 39.7 MB\n",
      "测试集信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75818 entries, 0 to 75817\n",
      "Columns: 105 entries, ID to var15_0\n",
      "dtypes: category(43), float64(29), int64(33)\n",
      "memory usage: 39.0 MB\n"
     ]
    }
   ],
   "source": [
    "def encode_categories(train, test, target_column):\n",
    "    # 遍历所有列，找到唯一值小于10个的列，不包括目标列\n",
    "    columns_to_recode = [column for column in train.columns if column != target_column and train[column].nunique() < 10]\n",
    "    \n",
    "    for column in columns_to_recode:\n",
    "        # 将列的数据类型修改为分类数据\n",
    "        combined = pd.concat([train[[column]], test[[column]]], axis=0)\n",
    "        combined[column] = combined[column].astype('category')\n",
    "        \n",
    "        # 为训练集和测试集重新编码\n",
    "        train[column], test[column] = combined.iloc[:len(train)], combined.iloc[len(train):]\n",
    "        train[column] = train[column].cat.codes + 1  # 从1开始编码\n",
    "        test[column] = test[column].cat.codes + 1\n",
    "\n",
    "    # 将修改后的列转换为category类型，确保一致性\n",
    "    for column in columns_to_recode:\n",
    "        train[column] = train[column].astype('category')\n",
    "        test[column] = test[column].astype('category')\n",
    "\n",
    "    # 打印信息确认\n",
    "    print(\"训练集信息：\")\n",
    "    train.info()\n",
    "    print(\"测试集信息：\")\n",
    "    test.info()\n",
    "\n",
    "encode_categories(train, test, 'TARGET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85646305-b0fe-45ed-88ef-ca6d5ac33ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(train['TARGET'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0214e-b982-45a3-8002-445b069993b0",
   "metadata": {},
   "source": [
    "- 在这里我们已经对潜在的分类数据进行了编码处理，并保证了不改变TARGET列，以便于下面的独热编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76779e5-bc03-4481-ae0d-311ab661f64c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **独热编码**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a744e6-59b8-4fa9-8846-84497b44e308",
   "metadata": {},
   "source": [
    "- 下面对刚才改变的category，对他们进行独热编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8f7251-6a1a-405b-b4e5-e4566295700e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(train, test):\n",
    "    # 独热编码：首先标识训练集和测试集中的分类列\n",
    "    train_category_columns = train.select_dtypes(include=['category']).columns\n",
    "    test_category_columns = test.select_dtypes(include=['category']).columns\n",
    "    \n",
    "    # 确保测试集和训练集有相同的分类列进行独热编码\n",
    "    common_category_columns = train_category_columns.intersection(test_category_columns)\n",
    "    \n",
    "    # 对训练集和测试集应用独热编码\n",
    "    train = pd.get_dummies(train, columns=common_category_columns, drop_first=True)\n",
    "    test = pd.get_dummies(test, columns=common_category_columns, drop_first=True)\n",
    "    \n",
    "    # 处理布尔型数据：将布尔型转换为整型，再转为分类型\n",
    "    for dataset in [train, test]:\n",
    "        for column in dataset.columns:\n",
    "            if dataset[column].nunique() == 2 and dataset[column].dtype == bool:\n",
    "                dataset[column] = dataset[column].astype(int).astype('category')\n",
    "\n",
    "    # 打印信息确认\n",
    "    print(\"训练集类型和形状：\")\n",
    "    print(train.dtypes)\n",
    "    print(train.shape)\n",
    "    \n",
    "    print(\"测试集类型和形状：\")\n",
    "    print(test.dtypes)\n",
    "    print(test.shape)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d991db66-3dc7-4f44-85f9-54ec33e67fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集类型和形状：\n",
      "ID                                 int64\n",
      "var3                               int64\n",
      "imp_ent_var16_ult1               float64\n",
      "imp_op_var39_comer_ult1          float64\n",
      "imp_op_var39_comer_ult3          float64\n",
      "                                  ...   \n",
      "num_meses_var13_corto_ult3_4    category\n",
      "num_meses_var39_vig_ult3_2      category\n",
      "num_meses_var39_vig_ult3_3      category\n",
      "num_meses_var39_vig_ult3_4      category\n",
      "var15_0_2                       category\n",
      "Length: 184, dtype: object\n",
      "(76020, 184)\n",
      "测试集类型和形状：\n",
      "ID                                 int64\n",
      "var3                               int64\n",
      "imp_ent_var16_ult1               float64\n",
      "imp_op_var39_comer_ult1          float64\n",
      "imp_op_var39_comer_ult3          float64\n",
      "                                  ...   \n",
      "num_meses_var13_corto_ult3_4    category\n",
      "num_meses_var39_vig_ult3_2      category\n",
      "num_meses_var39_vig_ult3_3      category\n",
      "num_meses_var39_vig_ult3_4      category\n",
      "var15_0_2                       category\n",
      "Length: 183, dtype: object\n",
      "(75818, 183)\n"
     ]
    }
   ],
   "source": [
    "train_processed, test_processed = process_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4acd31-9c91-47c5-83c8-60aa8648497c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 184 entries, ID to var15_0_2\n",
      "dtypes: category(121), float64(29), int64(34)\n",
      "memory usage: 45.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d49f6-8d38-4447-85e1-e2c3cea25684",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **多项式特征构造**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4380142-227b-4400-9640-176a113041b6",
   "metadata": {},
   "source": [
    "- 这里我们对数值型数据进行多项式特征构造，来看各种特征之间的交互作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749547e3-2c05-4f34-996b-89f5cd254dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_polynomial_features(train, test, target_column='TARGET', id_column='ID', degree=2):\n",
    "    # 创建多项式特征生成器，设定最高次数为2\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    \n",
    "    # 筛选出非ID、非TARGET且非category类型的列\n",
    "    feature_cols = [col for col in train.columns if col not in [id_column, target_column] and train[col].dtype != 'category']\n",
    "    \n",
    "    # 应用多项式特征转换到所选列\n",
    "    train_poly = poly.fit_transform(train[feature_cols])\n",
    "    test_poly = poly.transform(test[feature_cols])\n",
    "    \n",
    "    # 将生成的多项式特征转换为DataFrame\n",
    "    train_poly_df = pd.DataFrame(train_poly, columns=poly.get_feature_names_out(feature_cols), index=train.index)\n",
    "    test_poly_df = pd.DataFrame(test_poly, columns=poly.get_feature_names_out(feature_cols), index=test.index)\n",
    "    \n",
    "    # 合并原始数据集中的ID、TARGET和category列与新生成的多项式特征\n",
    "    train_final = pd.concat([train[[id_column, target_column] + list(train.select_dtypes('category').columns)], train_poly_df], axis=1)\n",
    "    test_final = pd.concat([test[[id_column] + list(test.select_dtypes('category').columns)], test_poly_df], axis=1)\n",
    "    \n",
    "    return train_final, test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d823fea-531d-4f80-94bf-96f262db8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_1, test_processed_1 = generate_polynomial_features(train_processed, test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6210678e-acce-4bf5-a963-c38f89765fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 2075 entries, ID to var38^2\n",
      "dtypes: category(121), float64(1952), int64(2)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "train_processed_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6faf652c-0b3c-43da-beb2-006096c15ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75818 entries, 0 to 75817\n",
      "Columns: 2074 entries, ID to var38^2\n",
      "dtypes: category(121), float64(1952), int64(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "test_processed_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850efd8-0a02-4f90-a806-0e42d71ce20c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7650249-b107-40f7-897a-87bec02ffc15",
   "metadata": {},
   "source": [
    "- 构造完特征后我们对特征之间，特征与目标变量之间相关性高的进行删除，防止多重共线性，保证特征是独立的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b0b49d0-a767-488d-815c-dfeda65abdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_corr_var(train, test, target_threshold=0.001, within_threshold=0.95):\n",
    "    \"\"\"\n",
    "    删除与目标变量相关性低的特征，删除彼此之间相关性高的特征（保留一个）\n",
    "    \"\"\"\n",
    "    # 计算训练集相关性矩阵\n",
    "    corr = train.drop(\"ID\", axis=1).corr().abs()\n",
    "    # 筛选与目标变量相关性低的特征\n",
    "    corr_target = corr['TARGET'].sort_values()\n",
    "    low_corr_features = corr_target[corr_target <= target_threshold].index.tolist()\n",
    "    print(f\"有 {len(low_corr_features)} 个特征因为与目标变量TARGET的相关系数绝对值小于 {target_threshold} 而被删除\")\n",
    "\n",
    "    # 确保只删除在训练集和测试集都存在的特征\n",
    "    low_corr_features = [feat for feat in low_corr_features if feat in train.columns and feat in test.columns]\n",
    "    train.drop(low_corr_features, axis=1, inplace=True)\n",
    "    test.drop(low_corr_features, axis=1, inplace=True)\n",
    "\n",
    "    # 删除彼此之间相关性高的特征\n",
    "    corr = train.drop([\"ID\", \"TARGET\"], axis=1).corr().abs()\n",
    "    upper_tri = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > within_threshold)]\n",
    "    print(f\"有 {len(to_drop)} 个特征与另一个特征高度相关且相关系数为 {within_threshold} 及以上而被删除\")\n",
    "\n",
    "    # 确保只删除在训练集和测试集都存在的特征\n",
    "    to_drop = [col for col in to_drop if col in train.columns and col in test.columns]\n",
    "    train.drop(to_drop, axis=1, inplace=True)\n",
    "    test.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    print(f\"特征数变成 {train.shape[1]} 个，其中特征已被删除\")\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b2d43b-cc7d-4204-8eb6-b949a087aab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 143 个特征因为与目标变量TARGET的相关系数绝对值小于 0.001 而被删除\n",
      "有 1014 个特征与另一个特征高度相关且相关系数为 0.95 及以上而被删除\n",
      "特征数变成 934 个，其中特征已被删除\n"
     ]
    }
   ],
   "source": [
    "train_processed_2, test_processed_2 = remove_corr_var(train_processed_1, test_processed_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ee50d0-d33b-4428-8f3e-5669d8f63b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 934 entries, ID to saldo_medio_var5_ult3 saldo_medio_var12_ult3\n",
      "dtypes: category(94), float64(838), int64(2)\n",
      "memory usage: 494.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_processed_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50bcf046-ea79-4941-b0c9-3f8f4be87ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75818 entries, 0 to 75817\n",
      "Columns: 933 entries, ID to saldo_medio_var5_ult3 saldo_medio_var12_ult3\n",
      "dtypes: category(94), float64(838), int64(1)\n",
      "memory usage: 492.1 MB\n"
     ]
    }
   ],
   "source": [
    "test_processed_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26efff-a10c-4554-aa0f-e790449eaa46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 特征增强"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f4ccd-77c5-4c4c-bb21-95d6ffd3f97d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **数据的标准化、归一化**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc864d-fcea-43d4-a92d-0cbd60006997",
   "metadata": {},
   "source": [
    "- 这里我们完成模型构造之前的标准化、归一化的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "690f462b-2f01-4ec6-b328-3fa61b03f335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train_processed_2.copy()\n",
    "x_test = test_processed_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d729fc3a-98f7-4a14-b881-a45417df52ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 934 entries, ID to saldo_medio_var5_ult3 saldo_medio_var12_ult3\n",
      "dtypes: category(94), float64(838), int64(2)\n",
      "memory usage: 494.0 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf6ca750-3882-46b6-bc98-313ae467c1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = x_train.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "# 创建 StandardScaler 对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对所选列进行标准化归一化\n",
    "x_train[columns_to_normalize] = scaler.fit_transform(x_train[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a3a831-5834-4813-a4c4-0362486941b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 934 entries, ID to saldo_medio_var5_ult3 saldo_medio_var12_ult3\n",
      "dtypes: category(94), float64(838), int64(2)\n",
      "memory usage: 494.0 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4839241d-c1a5-4de8-b161-37ad2b3f2ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = x_test.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "# 创建 StandardScaler 对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对所选列进行标准化归一化\n",
    "x_test[columns_to_normalize] = scaler.fit_transform(x_test[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ef2f3c-93cb-4a47-b1c1-a4cc3dcffad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75818 entries, 0 to 75817\n",
      "Columns: 933 entries, ID to saldo_medio_var5_ult3 saldo_medio_var12_ult3\n",
      "dtypes: category(94), float64(838), int64(1)\n",
      "memory usage: 492.1 MB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a7da2e8-367f-4dd4-9567-72be4be9a1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在x_train中不共有的列名: Index(['TARGET', 'num_var12_0_5', 'num_var12_0_7', 'num_var12_4',\n",
      "       'num_var24_0_4', 'num_var30_10', 'num_var39_0_7', 'num_var41_0_6',\n",
      "       'num_var41_0_7', 'num_var42_0_7', 'num_var42_0_9', 'num_var42_7',\n",
      "       'num_var5_0_6', 'num_var5_6'],\n",
      "      dtype='object')\n",
      "在x_test中不共有的列名: Index(['num_var12_0_6', 'num_var13_0_8', 'num_var13_8', 'num_var30_9',\n",
      "       'num_var39_0_11', 'num_var39_0_9', 'num_var41_0_11', 'num_var41_0_9',\n",
      "       'num_var42_0_8', 'num_var4_10', 'num_var4_9', 'num_var5_0_5',\n",
      "       'num_var5_5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 找出 data1 和 data2 中不共有的列名\n",
    "unique_columns_x_train = x_train.columns.difference(x_test.columns)\n",
    "unique_columns_x_test = x_test.columns.difference(x_train.columns)\n",
    "\n",
    "print(\"在x_train中不共有的列名:\", unique_columns_x_train)\n",
    "print(\"在x_test中不共有的列名:\", unique_columns_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2a5f7b-cfd5-43e9-8ece-2ae9f401434c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train.to_csv('x_train.csv', index=False)\n",
    "\n",
    "# 保存 x_test 到 CSV 文件\n",
    "x_test.to_csv('x_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152637e3-e801-4a45-8828-64345a884d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. 特征变换（PCA-LDA降维）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23d080-d538-4ddc-a012-72c883430002",
   "metadata": {},
   "source": [
    "- 由于特征筛选后还有900多个特征，所以这里采用特征变换（降维的方法）。而这里在机器学习流水线中，我们一般采用的是PCA和LDA两种方法结合应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7133cfe9-6697-479c-a7a2-e0ab80ae1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "x_train = pd.read_csv('x_train.csv')\n",
    "x_test = pd.read_csv('x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd17dab-a2be-4ef8-8acc-024f0f6cad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['num_var12_0_5', 'num_var12_0_7', 'num_var12_4', 'num_var24_0_4', 'num_var30_10',\n",
    "                   'num_var39_0_7', 'num_var41_0_6', 'num_var41_0_7', 'num_var42_0_7', 'num_var42_0_9',\n",
    "                   'num_var42_7', 'num_var5_0_6', 'num_var5_6', 'num_var12_0_6', 'num_var13_0_8',\n",
    "                   'num_var13_8', 'num_var30_9', 'num_var39_0_11', 'num_var39_0_9', 'num_var41_0_11',\n",
    "                   'num_var41_0_9', 'num_var42_0_8', 'num_var4_10', 'num_var4_9', 'num_var5_0_5',\n",
    "                   'num_var5_5']\n",
    "\n",
    "# 从 x_train 中删除指定列\n",
    "for col in columns_to_drop:\n",
    "    if col in x_train.columns:\n",
    "        x_train.drop(columns=col, inplace=True)\n",
    "\n",
    "# 从 x_test 中删除指定列\n",
    "for col in columns_to_drop:\n",
    "    if col in x_test.columns:\n",
    "        x_test.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f1ea6f4-00f2-46a2-b7eb-77d7af743933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 98% variance: 305\n"
     ]
    }
   ],
   "source": [
    "# 分离特征和标签\n",
    "X_train = x_train.drop(['TARGET', 'ID'], axis=1)\n",
    "y_train = x_train['TARGET']\n",
    "X_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "# 计算PCA需要保留的组件数以解释至少98%的方差\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.98) + 1  # 加1因为索引从0开始\n",
    "\n",
    "print(f\"Number of components to explain 98% variance: {d}\")\n",
    "\n",
    "# 使用计算出的组件数设置PCA\n",
    "pca = PCA(n_components=d)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# 应用LDA\n",
    "lda = LDA()\n",
    "X_train_lda = lda.fit_transform(X_train_pca, y_train)\n",
    "X_test_lda = lda.transform(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4832b-1608-43b0-86c7-36e83ae2a3cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **保存数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65ed99f8-b5b5-4e2a-8ce1-608211700299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将X_train_lda转换为DataFrame\n",
    "train_final = pd.DataFrame(X_train_lda, columns=[f'component_{i}' for i in range(X_train_lda.shape[1])])\n",
    "\n",
    "# 将y_train转换为DataFrame并与X_train_lda合并\n",
    "train_final['TARGET'] = y_train\n",
    "\n",
    "# 将数据保存为CSV文件\n",
    "train_final.to_csv('train_final.csv', index=False)\n",
    "\n",
    "# 将X_test_lda转换为DataFrame\n",
    "test_final = pd.DataFrame(X_test_lda, columns=[f'component_{i}' for i in range(X_test_lda.shape[1])])\n",
    "\n",
    "# 将数据保存为CSV文件\n",
    "test_final.to_csv('test_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
