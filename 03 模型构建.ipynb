{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e553ba2a-796d-4f3d-9f94-da896f28d189",
   "metadata": {},
   "source": [
    "## **构造XGBoost模型进行预测**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13156324-3416-4588-a019-cb172c7a81b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1. 前置操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11a0619e-2c7a-45a2-b96a-1dc4bcc2ba7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 常规包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# xgboost包\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c08e3-daff-4f23-8dd7-043130e7abc2",
   "metadata": {},
   "source": [
    "- 这里不知道怎么调试，我一直导入数据结果和之前结果不一样，我直接把上一步的特征工程最后一步降维搬过来了。这样结果就一样了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38c3673c-8815-4d95-81bd-b5368c22f0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 98% variance: 305\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "x_train = pd.read_csv('x_train.csv')\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "\n",
    "columns_to_drop = ['num_var12_0_5', 'num_var12_0_7', 'num_var12_4', 'num_var24_0_4', 'num_var30_10',\n",
    "                   'num_var39_0_7', 'num_var41_0_6', 'num_var41_0_7', 'num_var42_0_7', 'num_var42_0_9',\n",
    "                   'num_var42_7', 'num_var5_0_6', 'num_var5_6', 'num_var12_0_6', 'num_var13_0_8',\n",
    "                   'num_var13_8', 'num_var30_9', 'num_var39_0_11', 'num_var39_0_9', 'num_var41_0_11',\n",
    "                   'num_var41_0_9', 'num_var42_0_8', 'num_var4_10', 'num_var4_9', 'num_var5_0_5',\n",
    "                   'num_var5_5']\n",
    "\n",
    "# 从 x_train 中删除指定列\n",
    "for col in columns_to_drop:\n",
    "    if col in x_train.columns:\n",
    "        x_train.drop(columns=col, inplace=True)\n",
    "\n",
    "# 从 x_test 中删除指定列\n",
    "for col in columns_to_drop:\n",
    "    if col in x_test.columns:\n",
    "        x_test.drop(columns=col, inplace=True)\n",
    "\n",
    "        \n",
    "# 分离特征和标签\n",
    "X_train = x_train.drop(['TARGET', 'ID'], axis=1)\n",
    "y_train = x_train['TARGET']\n",
    "X_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "# 计算PCA需要保留的组件数以解释至少98%的方差\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.98) + 1  # 加1因为索引从0开始\n",
    "\n",
    "print(f\"Number of components to explain 98% variance: {d}\")\n",
    "\n",
    "# 使用计算出的组件数设置PCA\n",
    "pca = PCA(n_components=d)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# 应用LDA\n",
    "lda = LDA()\n",
    "X_train_lda = lda.fit_transform(X_train_pca, y_train)\n",
    "X_test_lda = lda.transform(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd86ce-2044-4ef7-a6b4-cf4c986df51f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2. 使用交叉验证平均得分评判**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b31cd-ffe3-49d8-863f-c16cd459964b",
   "metadata": {},
   "source": [
    "- 降维数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a72bbe9-ad17-46d6-a7d1-acfa1064d6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 创建XGBoost分类器\n",
    "model_lda = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# 进行交叉验证，这里使用5折交叉验证\n",
    "scores = cross_val_score(model_lda, X_train_lda, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# 输出交叉验证的平均得分和标准差\n",
    "print(f'Accuracy: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b886429-3653-4a0b-b74b-cd9b69810dd3",
   "metadata": {},
   "source": [
    "- 原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18c7e5f8-a310-4caa-a2af-1bfb46fc8efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with full features: 0.96 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 假设X_train和y_train是从你的x_train数据中提取的特征和目标变量\n",
    "X_train_full = train_1.drop(['TARGET'], axis=1)\n",
    "y_train = train_1['TARGET']\n",
    "\n",
    "# 创建XGBoost分类器\n",
    "model_full = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# 进行交叉验证，这里使用5折交叉验证\n",
    "scores_full = cross_val_score(model_full, X_train_full, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# 输出交叉验证的平均得分和标准差\n",
    "print(f'Accuracy with full features: {scores_full.mean():.2f} (+/- {scores_full.std() * 2:.2f})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23244fc8-e874-433f-a80b-2dc4e38337a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 两个平均得分都是0.96，这说明了我们模型拟合效果十分优秀。但也不仅思考，是不是出现过拟合了呢？为了防止出现过拟合的风险，我们不仅仅采取这一个评分标准，再采用AUC的评分标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0572b6f-7548-460f-83b2-f88df718b41b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **3.使用AUC评分**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb96bc-6fa1-4c02-8bb0-df5cf9ad77e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 降维后数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9e4753-6af9-4ede-be05-280793019e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best AUC: 0.765\n",
      "Validation AUC Score: 0.787\n"
     ]
    }
   ],
   "source": [
    "# 假设X_train_lda和y_train是降维后的数据和标签\n",
    "# 假设X_test_lda是降维后的测试数据\n",
    "\n",
    "# 划分数据集为训练集和验证集\n",
    "X_train_lda_split, X_val_lda, y_train_lda_split, y_val = train_test_split(\n",
    "    X_train_lda, y_train, stratify=y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "# 设置XGBoost模型参数\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# 参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],  # 树的最大深度\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # 学习率\n",
    "    'n_estimators': [50, 100, 150]  # 树的数量\n",
    "}\n",
    "\n",
    "# 创建网格搜索对象，使用3折交叉验证\n",
    "grid = GridSearchCV(model, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# 运行网格搜索\n",
    "grid.fit(X_train_lda_split, y_train_lda_split)\n",
    "\n",
    "# 输出最佳参数和最佳得分\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best AUC: {:.3f}\".format(grid.best_score_))\n",
    "\n",
    "# 使用最佳参数的模型在验证集上预测\n",
    "best_model = grid.best_estimator_\n",
    "val_predictions = best_model.predict_proba(X_val_lda)[:, 1]\n",
    "\n",
    "# 计算AUC得分\n",
    "auc_score = roc_auc_score(y_val, val_predictions)\n",
    "print(f'Validation AUC Score: {auc_score:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65905d-274b-4ed9-8921-c4f8d9b76fcd",
   "metadata": {},
   "source": [
    "- 原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1a3f81-4862-4bcc-b68c-9f9c5460e163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best AUC: 0.824\n",
      "Validation AUC Score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# 设置模型参数\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# 参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],  # 树的最大深度\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # 学习率\n",
    "    'n_estimators': [50, 100, 150]  # 树的数量\n",
    "}\n",
    "\n",
    "# 创建网格搜索对象，使用3折交叉验证\n",
    "grid = GridSearchCV(model, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# 划分数据集为训练集和验证集\n",
    "X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(X_full, y_full, stratify=y_full, test_size=0.15, random_state=42)\n",
    "\n",
    "# 运行网格搜索\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 输出最佳参数和最佳得分\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best AUC: {:.3f}\".format(grid.best_score_))\n",
    "\n",
    "# 使用最佳参数的模型在验证集上预测\n",
    "best_model = grid.best_estimator_\n",
    "val_predictions = best_model.predict_proba(X_val_full)[:, 1]\n",
    "\n",
    "# 计算AUC得分\n",
    "auc_score = roc_auc_score(y_val_full, val_predictions)\n",
    "print(f'Validation AUC Score: {auc_score:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24fbfa-7c6b-499f-8821-626f2fc13e1a",
   "metadata": {},
   "source": [
    "- 由上面可以发现，降维后数据虽然拟合速度较快，占用内存少，但是准确度得分不高。 \n",
    "- 而直接使用全部特征的得分更高，但是拟合速度十分缓慢。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeea1a0-4e73-48ce-ae60-eb2034f98add",
   "metadata": {
    "tags": []
   },
   "source": [
    "需要注意的是，由于我的笔记本的显卡是3050，并且kaggle的数据集上传出现了某些问题，无法使用kaggle的GPU。所以为了简化操作，这里的网格搜索和交叉验证进行超参数寻优的时候我只选择了很小的范围和3折。如果以后想改进模型，需要更好的电脑才能完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81fcba-2138-448c-a7c5-f39cde1d6edc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **至此所有的操作完成**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
